# Machine Learning | Evaluation Metrics and Model Validation
![image](https://github.com/Shariph7/DATA-SCIENCE/assets/158695717/d8ed7d43-9643-494a-9af0-c442bc98dc8c)

Evaluating a machine learning model is crucial to understand its performance and identify areas for improvement. it means if we built a model now, we have to check whether there is any problem in the model, where
is the place of improvement. This is simply a Evaluation Matrics.<br>
Evaluation metrics vary depending on the type of problem (classification or regression)<br>
# Classification Evaluation Metrics
1. Accuracy: simplest and most popular metric, but may not always be the best choice<br>
2. F1 Score: harmonic mean of precision and recall, provides a single number<br>
3. PR Curve: plots precision vs. recall, helps understand model performance<br>
4. ROC Curve: plots true positive rate vs. false positive rate, helps understand model performance<br>

# Regression Evaluation Metrics
1. Mean Absolute Error (MAE): sum of absolute errors, provides a simple measure of error<br>
2. Mean Squared Error (MSE): sum of squared errors, exaggerates the importance of larger errors<br>

# Conclusion
There are many evaluation metrics available, and it's essential to choose the right ones for your problem<br>
Research and understand the evaluation metrics before starting a project<br>
<h1>By Shariph Thapa</h1>
